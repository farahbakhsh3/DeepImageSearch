{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSearch4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farahbakhsh3/DeepImageSearch/blob/master/ImageSearch4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH1O7lOZEKnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install faiss-gpu\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiYGXFZA0wiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import build_montages\n",
        "import os\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.color import rgb2gray, gray2rgb\n",
        "from skimage.transform import resize\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "# import matplotlib\n",
        "# matplotlib.use('Agg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGp-ryGrCKSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print('[INFO] Tensorflow version ' + tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDxHbH2o7wyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir='/content/drive/My Drive/ImageSearch4/'\n",
        "cifar10model= base_dir + 'cifar10.h5'\n",
        "cifar10histplot= base_dir +  'cifar10histplot.png'\n",
        "cifar10modelplot= base_dir + 'cifar10modelplot.png'\n",
        "cifar10index= base_dir + 'cifar10index.pickle'\n",
        "cifar10chptweights= base_dir + 'cifar10weights.h5'\n",
        "\n",
        "LATENT_DIM= 1024\n",
        "WIDTH, HEIGTH, DEPTH= (32, 32, 3)\n",
        "\n",
        "EPOCHS= 150\n",
        "INIT_LR= 1e-3\n",
        "BATCH_SIZE= 32\n",
        "sample= 10\n",
        "classes= 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhQPNV-Zq5EL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('[INFO] loading cifar10 dataset...')\n",
        "((trainX, trainY), (testX, testY))= cifar10.load_data()\n",
        "trainX= trainX.astype('float32') / 255.0\n",
        "trainX= trainX.reshape(trainX.shape)\n",
        "print('Xtrain shape: ', trainX.shape)\n",
        "\n",
        "testX= testX.astype('float32') / 255.0\n",
        "testX= testX.reshape(testX.shape)\n",
        "print('Xtest shape: ', testX.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJrYtC240qxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build2(width, heigth, depth, latentDim=16):\n",
        "    inputs= layers.Input(shape=(width, heigth, depth), name='Inputs')\n",
        "    x= layers.Conv2D(32, (3, 3), strides=1, padding='same', activation='relu')(inputs)\n",
        "    x= layers.Conv2D(32, (3, 3), strides=2, padding='same', activation='relu')(inputs)\n",
        "    x= layers.BatchNormalization()(x)\n",
        "    x= layers.Dropout(0.25)(x)\n",
        "    x= layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
        "    x= layers.Conv2D(64, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
        "    x= layers.BatchNormalization()(x)\n",
        "    x= layers.Dropout(0.25)(x)\n",
        "    x= layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu')(x)\n",
        "    x= layers.Conv2D(128, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
        "    x= layers.BatchNormalization()(x)\n",
        "    x= layers.Dropout(0.25)(x)\n",
        "\n",
        "    volumeSize= K.int_shape(x)\n",
        "    x= layers.Flatten()(x)\n",
        "    latent= layers.Dense(latentDim, name='Encoded')(x)\n",
        "\n",
        "    x= layers.Dense(np.prod(volumeSize[1:]))(latent)\n",
        "    x= layers.Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n",
        "\n",
        "    x= layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
        "    x= layers.BatchNormalization()(x)\n",
        "    x= layers.Dropout(0.25)(x)\n",
        "    x= layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
        "    x= layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
        "    x= layers.BatchNormalization()(x)\n",
        "    x= layers.Dropout(0.25)(x)\n",
        "\n",
        "    x= layers.Conv2DTranspose(depth, (3, 3), strides=1, padding='same')(x)\n",
        "    outputs= layers.Activation('sigmoid', name='Decoded')(x)\n",
        "\n",
        "    x= layers.Dense(128, activation='relu')(latent)\n",
        "    x= layers.BatchNormalization()(x)\n",
        "    x= layers.Dropout(0.25)(x)\n",
        "    Classifier= layers.Dense(classes, activation='softmax', name='Classifier')(x)\n",
        "\n",
        "\n",
        "    model= Model(inputs=inputs, outputs=[outputs, Classifier])\n",
        "\n",
        "    return model\n",
        "    \n",
        "# ===============================\n",
        "\n",
        "def visualize_predictions(decoded, gt, samples=10):\n",
        "    outputs=None\n",
        "    for i in range(0, samples):\n",
        "        original= (gt[i] * 255).astype('uint8')\n",
        "        recon= (decoded[i] * 255).astype('uint8')\n",
        "        output= np.hstack([original, recon])\n",
        "        \n",
        "        if outputs is None:\n",
        "            outputs= output\n",
        "        else:\n",
        "            outputs= np.vstack([outputs, output])\n",
        "            \n",
        "    return outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RurRiiuCivxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('[INFO] building autoencoder...')\n",
        "# tpu= tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "# print('[INFO] Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "# tf.config.experimental_connect_to_cluster(tpu)\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "# strategy= tf.distribute.experimental.TPUStrategy(tpu)\n",
        "# print('[INFO] REPLICAS: ', strategy.num_replicas_in_sync)\n",
        "\n",
        "# with strategy.scope():\n",
        "autoencoder= build2(WIDTH, HEIGTH, DEPTH, latentDim=LATENT_DIM)\n",
        "plot_model(autoencoder, to_file=cifar10modelplot,\n",
        "           show_shapes=True)\n",
        "autoencoder.summary()\n",
        "\n",
        "# opt= Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "autoencoder.compile(loss=['mse', 'sparse_categorical_crossentropy'], optimizer='adam',\n",
        "                    metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCCiKY7B7GdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpointer= ModelCheckpoint(filepath=cifar10chptweights,\n",
        "                               verbose=0, save_best_only=True)\n",
        "H= autoencoder.fit(trainX, [trainX,trainY],\n",
        "                    validation_split=0.1,\n",
        "\t\t\t\t\tepochs=EPOCHS*4,\n",
        "\t\t\t\t\tbatch_size=BATCH_SIZE,\n",
        "\t\t\t\t\tverbose=2,\n",
        "\t\t\t\t\tcallbacks=[checkpointer])\n",
        "\n",
        "print('[INFO] saving autoencoder...')\n",
        "autoencoder.save(cifar10model, save_format='h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_304ZOW7pau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('[INFO] making predictions...')\n",
        "decoded= autoencoder.predict(testX)[0]\n",
        "vis= visualize_predictions(decoded, testX)\n",
        "cv2_imshow(vis)\n",
        "\n",
        "print('[INFO] makeing autoencoder plot ...')\n",
        "N= np.arange(0, EPOCHS)\n",
        "plt.style.use('ggplot')\n",
        "fig= plt.figure(figsize=(8,10))\n",
        "axs= fig.subplots(nrows=2, ncols=1)\n",
        "axs[0].plot(N, H.history['Decoded_loss'], label='Decoded_loss', color='g')\n",
        "axs[0].plot(N, H.history['val_Decoded_loss'], label='val_Decoded_loss', color='y')\n",
        "axs[1].plot(N, H.history['Classifier_accuracy'], label='Classifier_accuracy', color='tab:pink')\n",
        "axs[1].plot(N, H.history['val_Classifier_accuracy'], label='val_Classifier_accuracy', color='tab:brown')\n",
        "axs[1].set_xlabel('Epoch #')\n",
        "axs[1].set_ylabel('Loss/Accuracy')\n",
        "axs[0].legend(loc='upper right')\n",
        "axs[1].legend(loc='upper right')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqpF7V47jhCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print('[INFO] loading cifar10 training split...')\n",
        "# ((trainX, _), (testX, _))= cifar10.load_data()\n",
        "\n",
        "# trainX= trainX.astype('float32') / 255.0\n",
        "\n",
        "print('[INFO] loading autoencoder model...')\n",
        "autoencoder= load_model(cifar10model)\n",
        "\n",
        "encoder= Model(inputs=autoencoder.input,\n",
        "                outputs=autoencoder.get_layer('Encoded').output)\n",
        "\n",
        "print('[INFO] encoding images...')\n",
        "features= encoder.predict(trainX)\n",
        "\n",
        "indexes= list(range(0, trainX.shape[0]))\n",
        "data= {'indexes': indexes, 'features': features}\n",
        "\n",
        "print('[INFO] saving index...')\n",
        "f= open(cifar10index, 'wb')\n",
        "f.write(pickle.dumps(data))\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3FY1loMqX1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean(a, b):\n",
        "    diff= np.linalg.norm(a - b)\n",
        "    return diff\n",
        "\n",
        "def perform_search(queryFeatures, index, maxResults=64):\n",
        "\tresults= []\n",
        "\n",
        "\tfor i in range(0, len(index['features'])):\n",
        "\t\td= euclidean(queryFeatures, index['features'][i])\n",
        "\t\tresults.append((d, i))\n",
        "\n",
        "\tresults= sorted(results)[:maxResults]\n",
        "\n",
        "\treturn results\n",
        "\n",
        "# print('[INFO] loading cifar10 dataset...')\n",
        "# ((trainX, _), (testX, _))= cifar10.load_data()\n",
        "\n",
        "# trainX= trainX.astype('float32') / 255.0\n",
        "# testX= testX.astype('float32') / 255.0\n",
        "\n",
        "print('[INFO] loading autoencoder and index...')\n",
        "autoencoder= load_model(cifar10model)\n",
        "index= pickle.loads(open(cifar10index, 'rb').read())\n",
        "\n",
        "encoder= Model(inputs=autoencoder.input,\n",
        "                outputs=autoencoder.get_layer('Encoded').output)\n",
        "\n",
        "print('[INFO] encoding testing images...')\n",
        "features= encoder.predict(testX)\n",
        "\n",
        "queryIdxs= list(range(0, testX.shape[0]))\n",
        "queryIdxs= np.random.choice(queryIdxs, size=sample,\n",
        "                             replace=False)\n",
        "\n",
        "for i in queryIdxs:\n",
        "\tqueryFeatures= features[i]\n",
        "\tresults= perform_search(queryFeatures, index, 64)\n",
        "\timages= []\n",
        "\n",
        "\tfor (d, j) in results:\n",
        "\t\timage= (trainX[j] * 255).astype('uint8')\n",
        "\t\timages.append(image)\n",
        "\n",
        "\tquery= (testX[i] * 255).astype('uint8')\n",
        "\tcv2_imshow(cv2.resize(query, (64,64)))\n",
        "\n",
        "\tmontage= build_montages(images, (64, 64), (3, 3))[0]\n",
        "\tcv2_imshow(montage)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5gWAdpe2HF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}